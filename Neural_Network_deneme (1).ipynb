{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAHCuvik3wXy"
      },
      "source": [
        "# Building a Neural Network from Scratch\n",
        "\n",
        "https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naX7Yro73wYS"
      },
      "source": [
        "### Abstract Base Class : Layer\n",
        "The abstract class Layer, which all other layers will inherit from, handles simple properties which are an input, an output, and both a forward and backward methods."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jPaOyR-MTz8C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qkFnMHM3wYT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Base class\n",
        "class Layer:\n",
        "    def __init__(self):\n",
        "        self.input = None\n",
        "        self.output = None\n",
        "\n",
        "    # computes the output Y of a layer for a given input X\n",
        "    def forward_propagation(self, input):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    # computes dE/dX for a given dE/dY (and update parameters if any)\n",
        "    def backward_propagation(self, output_error, learning_rate):\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EGcwIdv3wYX"
      },
      "source": [
        "In the abstract class above, backward_propagation function has an extra parameter, learning_rate, which is controlling the amount of learning/updating parameters using gradient descent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwXoujFQ3wYY"
      },
      "source": [
        "### Backward Propagation\n",
        "Suppose we have a matrix containing the derivative of the error with respect to that layer’s output: $\\frac{\\partial E}{\\partial Y}$\n",
        "\n",
        "We need :\n",
        "- The derivative of the error with respect to the parameters ($\\frac{\\partial E}{\\partial W}$, $\\frac{\\partial E}{\\partial B}$)\n",
        "- The derivative of the error with respect to the input ($\\frac{\\partial E}{\\partial X}$)\n",
        "\n",
        "Let's calculate $\\frac{\\partial E}{\\partial W}$. This matrix should be the same size as $W$ itself : \n",
        "\n",
        "$i x j$ where $i$ is the number of input neurons and $j$ the number of output neurons. We need one gradient for every weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjZPifpJ3wYa"
      },
      "source": [
        "### Coding the Fully Connected Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDqvhL3L3wYb"
      },
      "outputs": [],
      "source": [
        "#from layer import Layer\n",
        "import numpy as np\n",
        "\n",
        "# inherit from base class Layer\n",
        "class FCLayer(Layer):\n",
        "    # input_size = number of input neurons\n",
        "    # output_size = number of edges that connects to neurons in next layer\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.weights = np.random.rand(input_size, output_size) - 0.5\n",
        "        self.bias = np.random.rand(1, output_size) - 0.5\n",
        "\n",
        "    # returns output for a given input\n",
        "    def forward_propagation(self, input_data):\n",
        "        self.input = input_data\n",
        "        self.output = np.dot(self.input, self.weights) + self.bias\n",
        "        return self.output\n",
        "\n",
        "    # computes dE/dW, dE/dB for a given output_error=dE/dY. Returns input_error=dE/dX.\n",
        "    def backward_propagation(self, output_error, learning_rate):\n",
        "        input_error = np.dot(output_error, self.weights.T)\n",
        "        weights_error = np.dot(self.input.T, output_error)\n",
        "        # dBias = output_error\n",
        "\n",
        "        # update parameters\n",
        "        self.weights -= learning_rate * weights_error\n",
        "        self.bias -= learning_rate * output_error\n",
        "        return input_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpreeJhb3wYd"
      },
      "source": [
        "### Activation Layer\n",
        "All the calculation we did until now were completely linear, may not learn well. We need to add non-linearity to the model by applying non-linear functions to the output of some layers.\n",
        "\n",
        "Now we need to redo the whole process for this new type of layer!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-VhJlxJ3wYg"
      },
      "outputs": [],
      "source": [
        "#from layer import Layer\n",
        "\n",
        "# inherit from base class Layer\n",
        "class ActivationLayer(Layer):\n",
        "    def __init__(self, activation, activation_prime):\n",
        "        self.activation = activation\n",
        "        self.activation_prime = activation_prime\n",
        "\n",
        "    # returns the activated input\n",
        "    def forward_propagation(self, input_data):\n",
        "        self.input = input_data\n",
        "        self.output = self.activation(self.input)\n",
        "        return self.output\n",
        "\n",
        "    # Returns input_error=dE/dX for a given output_error=dE/dY.\n",
        "    # learning_rate is not used because there is no \"learnable\" parameters.\n",
        "    def backward_propagation(self, output_error, learning_rate):\n",
        "        return self.activation_prime(self.input) * output_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qExBdJmG3wYh"
      },
      "source": [
        "You can also write some activation functions and their derivatives in a separate file. These will be used later to create an ActivationLayer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zdgKMMX3wYi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# activation function and its derivative\n",
        "def tanh(x):\n",
        "    return np.tanh(x);\n",
        "\n",
        "def tanh_prime(x):\n",
        "    return 1-np.tanh(x)**2;\n",
        "\n",
        "def Relu(x):\n",
        "  return (np.maximum(0,x))\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "def sigmoid_prime(z) :\n",
        "    \"\"\" Returns the derivative of the sigmoid function. \"\"\"\n",
        "    return sigmoid(z)*(1-sigmoid(z))\n",
        "\n",
        "def Relu_prime(z) :\n",
        "    \"\"\" Returns the derivative of the ReLU function. \"\"\"\n",
        "    return 1*(z>=0)    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7pJRJUf3wYj"
      },
      "source": [
        "### Loss Function\n",
        "Until now, for a given layer, we supposed that ∂E/∂Y was given (by the next layer). But what happens to the last layer? How does it get ∂E/∂Y? We simply give it manually, and it depends on how we define the error.\n",
        "The error of the network, which measures how good or bad the network did for a given input data, is defined by you. \n",
        "\n",
        "There are many ways to define the error, and one of the most known is called MSE — Mean Squared Error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoU52HHV3wYj"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# loss function and its derivative\n",
        "def mse(y_true, y_pred):\n",
        "    return np.mean(np.power(y_true-y_pred, 2));\n",
        "\n",
        "def mse_prime(y_true, y_pred):\n",
        "    return 2*(y_pred-y_true)/y_true.size;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk-WUe_43wYk"
      },
      "source": [
        "### Network Class\n",
        "Almost done ! We are going to make a Network class to create neural networks very easily using the building blocks we have prepared so far.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QhILoR13wYl"
      },
      "outputs": [],
      "source": [
        "# example of a function for calculating softmax for a list of numbers\n",
        "from numpy import exp\n",
        " \n",
        "# calculate the softmax of a vector\n",
        "def softmax(vector):\n",
        "    e = exp(vector)\n",
        "    return e / e.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jP3NTVF3wYm"
      },
      "outputs": [],
      "source": [
        "class Network:\n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "        self.loss = None\n",
        "        self.loss_prime = None\n",
        "\n",
        "    # add layer to network\n",
        "    def add(self, layer):\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    # set loss to use\n",
        "    def use(self, loss, loss_prime):\n",
        "        self.loss = loss\n",
        "        self.loss_prime = loss_prime\n",
        "\n",
        "        \n",
        "    # predict output for given input\n",
        "    def predict(self, input_data):\n",
        "        # sample dimension first\n",
        "        samples = len(input_data)\n",
        "        result = []\n",
        "\n",
        "        # run network over all samples\n",
        "        for i in range(samples):\n",
        "            # forward propagation\n",
        "            output = input_data[i]\n",
        "            for layer in self.layers:\n",
        "                output = layer.forward_propagation(output)\n",
        "            result.append(output)\n",
        "\n",
        "        return result\n",
        "\n",
        "    # train the network \n",
        "    \n",
        "    def fit(self, x_train, y_train, epochs, learning_rate):\n",
        "        '''\n",
        "        Fit function does the training. \n",
        "        Training data is passed 1-by-1 through the network layers during forward propagation.\n",
        "        Loss (error) is calculated for each input and back propagation is performed via partial \n",
        "        derivatives on each layer.\n",
        "        '''\n",
        "        # sample dimension first\n",
        "        samples = len(x_train)\n",
        "\n",
        "        # training loop\n",
        "        for i in range(epochs):\n",
        "            err = 0\n",
        "            for j in range(samples):\n",
        "                # forward propagation\n",
        "                output = x_train[j]\n",
        "                for layer in self.layers:\n",
        "                    output = layer.forward_propagation(output)\n",
        "\n",
        "                # compute loss (for display purpose only)\n",
        "                err += self.loss(y_train[j], output)\n",
        "\n",
        "                # backward propagation\n",
        "                error = self.loss_prime(y_train[j], output)\n",
        "                for layer in reversed(self.layers):\n",
        "                    error = layer.backward_propagation(error, learning_rate)\n",
        "\n",
        "            # calculate average error on all samples\n",
        "            err /= samples\n",
        "            print('epoch %d/%d   error=%f' % (i+1, epochs, err))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIYYvW4A3wYo"
      },
      "source": [
        "### Building Neural Networks\n",
        "Finally ! We can use our class to create a neural network with as many layers as we want ! We are going to build two neural networks : a simple XOR and a MNIST solver.\n",
        "\n",
        "\n",
        "### Solve XOR\n",
        "Starting with XOR is always important as it’s a simple way to tell if the network is learning anything at all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ukzxlns3wYo",
        "outputId": "295ee3a2-a33d-44e5-e709-f1870d32f374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/1000   error=0.264831\n",
            "epoch 2/1000   error=0.263669\n",
            "epoch 3/1000   error=0.262622\n",
            "epoch 4/1000   error=0.261676\n",
            "epoch 5/1000   error=0.260820\n",
            "epoch 6/1000   error=0.260042\n",
            "epoch 7/1000   error=0.259335\n",
            "epoch 8/1000   error=0.258958\n",
            "epoch 9/1000   error=0.258671\n",
            "epoch 10/1000   error=0.258417\n",
            "epoch 11/1000   error=0.258193\n",
            "epoch 12/1000   error=0.257993\n",
            "epoch 13/1000   error=0.257813\n",
            "epoch 14/1000   error=0.257652\n",
            "epoch 15/1000   error=0.257505\n",
            "epoch 16/1000   error=0.257371\n",
            "epoch 17/1000   error=0.257247\n",
            "epoch 18/1000   error=0.257133\n",
            "epoch 19/1000   error=0.257025\n",
            "epoch 20/1000   error=0.256923\n",
            "epoch 21/1000   error=0.256826\n",
            "epoch 22/1000   error=0.256733\n",
            "epoch 23/1000   error=0.256642\n",
            "epoch 24/1000   error=0.256554\n",
            "epoch 25/1000   error=0.256467\n",
            "epoch 26/1000   error=0.256380\n",
            "epoch 27/1000   error=0.256293\n",
            "epoch 28/1000   error=0.256206\n",
            "epoch 29/1000   error=0.256118\n",
            "epoch 30/1000   error=0.256029\n",
            "epoch 31/1000   error=0.255938\n",
            "epoch 32/1000   error=0.255844\n",
            "epoch 33/1000   error=0.255748\n",
            "epoch 34/1000   error=0.255648\n",
            "epoch 35/1000   error=0.255545\n",
            "epoch 36/1000   error=0.255466\n",
            "epoch 37/1000   error=0.255372\n",
            "epoch 38/1000   error=0.255296\n",
            "epoch 39/1000   error=0.255207\n",
            "epoch 40/1000   error=0.255111\n",
            "epoch 41/1000   error=0.255039\n",
            "epoch 42/1000   error=0.254935\n",
            "epoch 43/1000   error=0.254846\n",
            "epoch 44/1000   error=0.254759\n",
            "epoch 45/1000   error=0.254647\n",
            "epoch 46/1000   error=0.254569\n",
            "epoch 47/1000   error=0.254462\n",
            "epoch 48/1000   error=0.254349\n",
            "epoch 49/1000   error=0.254269\n",
            "epoch 50/1000   error=0.254141\n",
            "epoch 51/1000   error=0.254041\n",
            "epoch 52/1000   error=0.253935\n",
            "epoch 53/1000   error=0.253795\n",
            "epoch 54/1000   error=0.253713\n",
            "epoch 55/1000   error=0.253574\n",
            "epoch 56/1000   error=0.253439\n",
            "epoch 57/1000   error=0.253342\n",
            "epoch 58/1000   error=0.253178\n",
            "epoch 59/1000   error=0.253065\n",
            "epoch 60/1000   error=0.252927\n",
            "epoch 61/1000   error=0.252746\n",
            "epoch 62/1000   error=0.252663\n",
            "epoch 63/1000   error=0.252470\n",
            "epoch 64/1000   error=0.252317\n",
            "epoch 65/1000   error=0.252182\n",
            "epoch 66/1000   error=0.251967\n",
            "epoch 67/1000   error=0.251852\n",
            "epoch 68/1000   error=0.251653\n",
            "epoch 69/1000   error=0.251442\n",
            "epoch 70/1000   error=0.251320\n",
            "epoch 71/1000   error=0.251065\n",
            "epoch 72/1000   error=0.250901\n",
            "epoch 73/1000   error=0.250700\n",
            "epoch 74/1000   error=0.250418\n",
            "epoch 75/1000   error=0.250314\n",
            "epoch 76/1000   error=0.250010\n",
            "epoch 77/1000   error=0.249791\n",
            "epoch 78/1000   error=0.249586\n",
            "epoch 79/1000   error=0.249246\n",
            "epoch 80/1000   error=0.249106\n",
            "epoch 81/1000   error=0.248779\n",
            "epoch 82/1000   error=0.248483\n",
            "epoch 83/1000   error=0.248284\n",
            "epoch 84/1000   error=0.247879\n",
            "epoch 85/1000   error=0.247688\n",
            "epoch 86/1000   error=0.247333\n",
            "epoch 87/1000   error=0.246958\n",
            "epoch 88/1000   error=0.246755\n",
            "epoch 89/1000   error=0.246273\n",
            "epoch 90/1000   error=0.246040\n",
            "epoch 91/1000   error=0.245637\n",
            "epoch 92/1000   error=0.245191\n",
            "epoch 93/1000   error=0.244963\n",
            "epoch 94/1000   error=0.244390\n",
            "epoch 95/1000   error=0.244139\n",
            "epoch 96/1000   error=0.243648\n",
            "epoch 97/1000   error=0.243159\n",
            "epoch 98/1000   error=0.242865\n",
            "epoch 99/1000   error=0.242185\n",
            "epoch 100/1000   error=0.241963\n",
            "epoch 101/1000   error=0.241325\n",
            "epoch 102/1000   error=0.240844\n",
            "epoch 103/1000   error=0.240418\n",
            "epoch 104/1000   error=0.239667\n",
            "epoch 105/1000   error=0.239462\n",
            "epoch 106/1000   error=0.238605\n",
            "epoch 107/1000   error=0.238270\n",
            "epoch 108/1000   error=0.237561\n",
            "epoch 109/1000   error=0.236951\n",
            "epoch 110/1000   error=0.236463\n",
            "epoch 111/1000   error=0.235579\n",
            "epoch 112/1000   error=0.235310\n",
            "epoch 113/1000   error=0.234241\n",
            "epoch 114/1000   error=0.234003\n",
            "epoch 115/1000   error=0.232990\n",
            "epoch 116/1000   error=0.232498\n",
            "epoch 117/1000   error=0.231679\n",
            "epoch 118/1000   error=0.230952\n",
            "epoch 119/1000   error=0.230309\n",
            "epoch 120/1000   error=0.229369\n",
            "epoch 121/1000   error=0.228878\n",
            "epoch 122/1000   error=0.227756\n",
            "epoch 123/1000   error=0.227384\n",
            "epoch 124/1000   error=0.226118\n",
            "epoch 125/1000   error=0.225826\n",
            "epoch 126/1000   error=0.224463\n",
            "epoch 127/1000   error=0.224204\n",
            "epoch 128/1000   error=0.222796\n",
            "epoch 129/1000   error=0.222356\n",
            "epoch 130/1000   error=0.221846\n",
            "epoch 131/1000   error=0.220525\n",
            "epoch 132/1000   error=0.220139\n",
            "epoch 133/1000   error=0.219360\n",
            "epoch 134/1000   error=0.218455\n",
            "epoch 135/1000   error=0.217527\n",
            "epoch 136/1000   error=0.217051\n",
            "epoch 137/1000   error=0.216147\n",
            "epoch 138/1000   error=0.215799\n",
            "epoch 139/1000   error=0.213988\n",
            "epoch 140/1000   error=0.214157\n",
            "epoch 141/1000   error=0.213285\n",
            "epoch 142/1000   error=0.211650\n",
            "epoch 143/1000   error=0.211689\n",
            "epoch 144/1000   error=0.210957\n",
            "epoch 145/1000   error=0.209279\n",
            "epoch 146/1000   error=0.209290\n",
            "epoch 147/1000   error=0.208649\n",
            "epoch 148/1000   error=0.206815\n",
            "epoch 149/1000   error=0.207008\n",
            "epoch 150/1000   error=0.206363\n",
            "epoch 151/1000   error=0.204444\n",
            "epoch 152/1000   error=0.204641\n",
            "epoch 153/1000   error=0.204152\n",
            "epoch 154/1000   error=0.202412\n",
            "epoch 155/1000   error=0.202149\n",
            "epoch 156/1000   error=0.201710\n",
            "epoch 157/1000   error=0.200631\n",
            "epoch 158/1000   error=0.199063\n",
            "epoch 159/1000   error=0.199534\n",
            "epoch 160/1000   error=0.199078\n",
            "epoch 161/1000   error=0.197279\n",
            "epoch 162/1000   error=0.197214\n",
            "epoch 163/1000   error=0.196379\n",
            "epoch 164/1000   error=0.195868\n",
            "epoch 165/1000   error=0.194342\n",
            "epoch 166/1000   error=0.194590\n",
            "epoch 167/1000   error=0.193690\n",
            "epoch 168/1000   error=0.193083\n",
            "epoch 169/1000   error=0.191606\n",
            "epoch 170/1000   error=0.191915\n",
            "epoch 171/1000   error=0.190719\n",
            "epoch 172/1000   error=0.190493\n",
            "epoch 173/1000   error=0.189082\n",
            "epoch 174/1000   error=0.189251\n",
            "epoch 175/1000   error=0.187554\n",
            "epoch 176/1000   error=0.188079\n",
            "epoch 177/1000   error=0.186723\n",
            "epoch 178/1000   error=0.186566\n",
            "epoch 179/1000   error=0.185080\n",
            "epoch 180/1000   error=0.184754\n",
            "epoch 181/1000   error=0.184262\n",
            "epoch 182/1000   error=0.184274\n",
            "epoch 183/1000   error=0.183011\n",
            "epoch 184/1000   error=0.181821\n",
            "epoch 185/1000   error=0.181697\n",
            "epoch 186/1000   error=0.181006\n",
            "epoch 187/1000   error=0.181108\n",
            "epoch 188/1000   error=0.179909\n",
            "epoch 189/1000   error=0.178774\n",
            "epoch 190/1000   error=0.178505\n",
            "epoch 191/1000   error=0.177401\n",
            "epoch 192/1000   error=0.177882\n",
            "epoch 193/1000   error=0.177021\n",
            "epoch 194/1000   error=0.175900\n",
            "epoch 195/1000   error=0.174827\n",
            "epoch 196/1000   error=0.174791\n",
            "epoch 197/1000   error=0.173494\n",
            "epoch 198/1000   error=0.173877\n",
            "epoch 199/1000   error=0.173047\n",
            "epoch 200/1000   error=0.171948\n",
            "epoch 201/1000   error=0.170888\n",
            "epoch 202/1000   error=0.170652\n",
            "epoch 203/1000   error=0.169504\n",
            "epoch 204/1000   error=0.169070\n",
            "epoch 205/1000   error=0.168904\n",
            "epoch 206/1000   error=0.167785\n",
            "epoch 207/1000   error=0.166696\n",
            "epoch 208/1000   error=0.165632\n",
            "epoch 209/1000   error=0.165568\n",
            "epoch 210/1000   error=0.164139\n",
            "epoch 211/1000   error=0.163620\n",
            "epoch 212/1000   error=0.163305\n",
            "epoch 213/1000   error=0.162139\n",
            "epoch 214/1000   error=0.160991\n",
            "epoch 215/1000   error=0.159855\n",
            "epoch 216/1000   error=0.159468\n",
            "epoch 217/1000   error=0.158138\n",
            "epoch 218/1000   error=0.156968\n",
            "epoch 219/1000   error=0.156704\n",
            "epoch 220/1000   error=0.155960\n",
            "epoch 221/1000   error=0.154726\n",
            "epoch 222/1000   error=0.153456\n",
            "epoch 223/1000   error=0.152282\n",
            "epoch 224/1000   error=0.151847\n",
            "epoch 225/1000   error=0.150373\n",
            "epoch 226/1000   error=0.149034\n",
            "epoch 227/1000   error=0.148342\n",
            "epoch 228/1000   error=0.147660\n",
            "epoch 229/1000   error=0.146198\n",
            "epoch 230/1000   error=0.144857\n",
            "epoch 231/1000   error=0.143592\n",
            "epoch 232/1000   error=0.142087\n",
            "epoch 233/1000   error=0.141278\n",
            "epoch 234/1000   error=0.139856\n",
            "epoch 235/1000   error=0.138255\n",
            "epoch 236/1000   error=0.136815\n",
            "epoch 237/1000   error=0.136240\n",
            "epoch 238/1000   error=0.134649\n",
            "epoch 239/1000   error=0.132896\n",
            "epoch 240/1000   error=0.131347\n",
            "epoch 241/1000   error=0.129842\n",
            "epoch 242/1000   error=0.128017\n",
            "epoch 243/1000   error=0.127148\n",
            "epoch 244/1000   error=0.125264\n",
            "epoch 245/1000   error=0.123334\n",
            "epoch 246/1000   error=0.121250\n",
            "epoch 247/1000   error=0.120827\n",
            "epoch 248/1000   error=0.119174\n",
            "epoch 249/1000   error=0.117091\n",
            "epoch 250/1000   error=0.114788\n",
            "epoch 251/1000   error=0.113805\n",
            "epoch 252/1000   error=0.111887\n",
            "epoch 253/1000   error=0.110401\n",
            "epoch 254/1000   error=0.108749\n",
            "epoch 255/1000   error=0.106240\n",
            "epoch 256/1000   error=0.104687\n",
            "epoch 257/1000   error=0.102961\n",
            "epoch 258/1000   error=0.102353\n",
            "epoch 259/1000   error=0.099982\n",
            "epoch 260/1000   error=0.097834\n",
            "epoch 261/1000   error=0.096882\n",
            "epoch 262/1000   error=0.094623\n",
            "epoch 263/1000   error=0.093232\n",
            "epoch 264/1000   error=0.091352\n",
            "epoch 265/1000   error=0.089923\n",
            "epoch 266/1000   error=0.088089\n",
            "epoch 267/1000   error=0.085812\n",
            "epoch 268/1000   error=0.084777\n",
            "epoch 269/1000   error=0.084025\n",
            "epoch 270/1000   error=0.082191\n",
            "epoch 271/1000   error=0.080367\n",
            "epoch 272/1000   error=0.078390\n",
            "epoch 273/1000   error=0.077505\n",
            "epoch 274/1000   error=0.075569\n",
            "epoch 275/1000   error=0.074137\n",
            "epoch 276/1000   error=0.073225\n",
            "epoch 277/1000   error=0.071012\n",
            "epoch 278/1000   error=0.070862\n",
            "epoch 279/1000   error=0.068784\n",
            "epoch 280/1000   error=0.068341\n",
            "epoch 281/1000   error=0.066057\n",
            "epoch 282/1000   error=0.065640\n",
            "epoch 283/1000   error=0.063523\n",
            "epoch 284/1000   error=0.063519\n",
            "epoch 285/1000   error=0.061446\n",
            "epoch 286/1000   error=0.060718\n",
            "epoch 287/1000   error=0.059230\n",
            "epoch 288/1000   error=0.058864\n",
            "epoch 289/1000   error=0.057908\n",
            "epoch 290/1000   error=0.056289\n",
            "epoch 291/1000   error=0.055414\n",
            "epoch 292/1000   error=0.054375\n",
            "epoch 293/1000   error=0.053681\n",
            "epoch 294/1000   error=0.052607\n",
            "epoch 295/1000   error=0.051087\n",
            "epoch 296/1000   error=0.050839\n",
            "epoch 297/1000   error=0.050363\n",
            "epoch 298/1000   error=0.049174\n",
            "epoch 299/1000   error=0.048446\n",
            "epoch 300/1000   error=0.047063\n",
            "epoch 301/1000   error=0.046801\n",
            "epoch 302/1000   error=0.046152\n",
            "epoch 303/1000   error=0.045099\n",
            "epoch 304/1000   error=0.044724\n",
            "epoch 305/1000   error=0.043637\n",
            "epoch 306/1000   error=0.043157\n",
            "epoch 307/1000   error=0.042637\n",
            "epoch 308/1000   error=0.041648\n",
            "epoch 309/1000   error=0.041448\n",
            "epoch 310/1000   error=0.040275\n",
            "epoch 311/1000   error=0.039814\n",
            "epoch 312/1000   error=0.039661\n",
            "epoch 313/1000   error=0.038607\n",
            "epoch 314/1000   error=0.038224\n",
            "epoch 315/1000   error=0.037688\n",
            "epoch 316/1000   error=0.036958\n",
            "epoch 317/1000   error=0.036672\n",
            "epoch 318/1000   error=0.036074\n",
            "epoch 319/1000   error=0.035443\n",
            "epoch 320/1000   error=0.035154\n",
            "epoch 321/1000   error=0.034714\n",
            "epoch 322/1000   error=0.033764\n",
            "epoch 323/1000   error=0.033822\n",
            "epoch 324/1000   error=0.033259\n",
            "epoch 325/1000   error=0.032570\n",
            "epoch 326/1000   error=0.032461\n",
            "epoch 327/1000   error=0.032054\n",
            "epoch 328/1000   error=0.031188\n",
            "epoch 329/1000   error=0.031202\n",
            "epoch 330/1000   error=0.030753\n",
            "epoch 331/1000   error=0.030004\n",
            "epoch 332/1000   error=0.030061\n",
            "epoch 333/1000   error=0.029691\n",
            "epoch 334/1000   error=0.028974\n",
            "epoch 335/1000   error=0.028653\n",
            "epoch 336/1000   error=0.028680\n",
            "epoch 337/1000   error=0.027968\n",
            "epoch 338/1000   error=0.027806\n",
            "epoch 339/1000   error=0.027475\n",
            "epoch 340/1000   error=0.027169\n",
            "epoch 341/1000   error=0.026533\n",
            "epoch 342/1000   error=0.026642\n",
            "epoch 343/1000   error=0.025962\n",
            "epoch 344/1000   error=0.026095\n",
            "epoch 345/1000   error=0.025611\n",
            "epoch 346/1000   error=0.025213\n",
            "epoch 347/1000   error=0.024971\n",
            "epoch 348/1000   error=0.024710\n",
            "epoch 349/1000   error=0.024479\n",
            "epoch 350/1000   error=0.024146\n",
            "epoch 351/1000   error=0.024024\n",
            "epoch 352/1000   error=0.023626\n",
            "epoch 353/1000   error=0.023310\n",
            "epoch 354/1000   error=0.023263\n",
            "epoch 355/1000   error=0.022817\n",
            "epoch 356/1000   error=0.022818\n",
            "epoch 357/1000   error=0.022337\n",
            "epoch 358/1000   error=0.022183\n",
            "epoch 359/1000   error=0.021986\n",
            "epoch 360/1000   error=0.021710\n",
            "epoch 361/1000   error=0.021493\n",
            "epoch 362/1000   error=0.021390\n",
            "epoch 363/1000   error=0.021117\n",
            "epoch 364/1000   error=0.020803\n",
            "epoch 365/1000   error=0.020635\n",
            "epoch 366/1000   error=0.020496\n",
            "epoch 367/1000   error=0.020303\n",
            "epoch 368/1000   error=0.020123\n",
            "epoch 369/1000   error=0.019834\n",
            "epoch 370/1000   error=0.019711\n",
            "epoch 371/1000   error=0.019575\n",
            "epoch 372/1000   error=0.019223\n",
            "epoch 373/1000   error=0.019199\n",
            "epoch 374/1000   error=0.018961\n",
            "epoch 375/1000   error=0.018767\n",
            "epoch 376/1000   error=0.018580\n",
            "epoch 377/1000   error=0.018436\n",
            "epoch 378/1000   error=0.018268\n",
            "epoch 379/1000   error=0.018185\n",
            "epoch 380/1000   error=0.017810\n",
            "epoch 381/1000   error=0.017879\n",
            "epoch 382/1000   error=0.017600\n",
            "epoch 383/1000   error=0.017493\n",
            "epoch 384/1000   error=0.017298\n",
            "epoch 385/1000   error=0.017169\n",
            "epoch 386/1000   error=0.016981\n",
            "epoch 387/1000   error=0.016946\n",
            "epoch 388/1000   error=0.016680\n",
            "epoch 389/1000   error=0.016552\n",
            "epoch 390/1000   error=0.016441\n",
            "epoch 391/1000   error=0.016327\n",
            "epoch 392/1000   error=0.016195\n",
            "epoch 393/1000   error=0.016058\n",
            "epoch 394/1000   error=0.015809\n",
            "epoch 395/1000   error=0.015809\n",
            "epoch 396/1000   error=0.015615\n",
            "epoch 397/1000   error=0.015595\n",
            "epoch 398/1000   error=0.015356\n",
            "epoch 399/1000   error=0.015234\n",
            "epoch 400/1000   error=0.015133\n",
            "epoch 401/1000   error=0.015076\n",
            "epoch 402/1000   error=0.014852\n",
            "epoch 403/1000   error=0.014822\n",
            "epoch 404/1000   error=0.014654\n",
            "epoch 405/1000   error=0.014484\n",
            "epoch 406/1000   error=0.014534\n",
            "epoch 407/1000   error=0.014301\n",
            "epoch 408/1000   error=0.014269\n",
            "epoch 409/1000   error=0.014057\n",
            "epoch 410/1000   error=0.014034\n",
            "epoch 411/1000   error=0.013910\n",
            "epoch 412/1000   error=0.013813\n",
            "epoch 413/1000   error=0.013621\n",
            "epoch 414/1000   error=0.013670\n",
            "epoch 415/1000   error=0.013450\n",
            "epoch 416/1000   error=0.013460\n",
            "epoch 417/1000   error=0.013275\n",
            "epoch 418/1000   error=0.013131\n",
            "epoch 419/1000   error=0.013145\n",
            "epoch 420/1000   error=0.013036\n",
            "epoch 421/1000   error=0.012944\n",
            "epoch 422/1000   error=0.012790\n",
            "epoch 423/1000   error=0.012724\n",
            "epoch 424/1000   error=0.012632\n",
            "epoch 425/1000   error=0.012598\n",
            "epoch 426/1000   error=0.012464\n",
            "epoch 427/1000   error=0.012390\n",
            "epoch 428/1000   error=0.012297\n",
            "epoch 429/1000   error=0.012237\n",
            "epoch 430/1000   error=0.012113\n",
            "epoch 431/1000   error=0.012038\n",
            "epoch 432/1000   error=0.012009\n",
            "epoch 433/1000   error=0.011827\n",
            "epoch 434/1000   error=0.011852\n",
            "epoch 435/1000   error=0.011736\n",
            "epoch 436/1000   error=0.011648\n",
            "epoch 437/1000   error=0.011575\n",
            "epoch 438/1000   error=0.011496\n",
            "epoch 439/1000   error=0.011420\n",
            "epoch 440/1000   error=0.011389\n",
            "epoch 441/1000   error=0.011252\n",
            "epoch 442/1000   error=0.011148\n",
            "epoch 443/1000   error=0.011160\n",
            "epoch 444/1000   error=0.011028\n",
            "epoch 445/1000   error=0.011084\n",
            "epoch 446/1000   error=0.010879\n",
            "epoch 447/1000   error=0.010830\n",
            "epoch 448/1000   error=0.010814\n",
            "epoch 449/1000   error=0.010724\n",
            "epoch 450/1000   error=0.010670\n",
            "epoch 451/1000   error=0.010576\n",
            "epoch 452/1000   error=0.010512\n",
            "epoch 453/1000   error=0.010447\n",
            "epoch 454/1000   error=0.010408\n",
            "epoch 455/1000   error=0.010340\n",
            "epoch 456/1000   error=0.010276\n",
            "epoch 457/1000   error=0.010186\n",
            "epoch 458/1000   error=0.010137\n",
            "epoch 459/1000   error=0.010085\n",
            "epoch 460/1000   error=0.009975\n",
            "epoch 461/1000   error=0.010044\n",
            "epoch 462/1000   error=0.009879\n",
            "epoch 463/1000   error=0.009870\n",
            "epoch 464/1000   error=0.009793\n",
            "epoch 465/1000   error=0.009723\n",
            "epoch 466/1000   error=0.009687\n",
            "epoch 467/1000   error=0.009623\n",
            "epoch 468/1000   error=0.009592\n",
            "epoch 469/1000   error=0.009491\n",
            "epoch 470/1000   error=0.009459\n",
            "epoch 471/1000   error=0.009404\n",
            "epoch 472/1000   error=0.009368\n",
            "epoch 473/1000   error=0.009314\n",
            "epoch 474/1000   error=0.009217\n",
            "epoch 475/1000   error=0.009195\n",
            "epoch 476/1000   error=0.009148\n",
            "epoch 477/1000   error=0.009129\n",
            "epoch 478/1000   error=0.009006\n",
            "epoch 479/1000   error=0.009029\n",
            "epoch 480/1000   error=0.008938\n",
            "epoch 481/1000   error=0.008933\n",
            "epoch 482/1000   error=0.008843\n",
            "epoch 483/1000   error=0.008769\n",
            "epoch 484/1000   error=0.008785\n",
            "epoch 485/1000   error=0.008698\n",
            "epoch 486/1000   error=0.008695\n",
            "epoch 487/1000   error=0.008601\n",
            "epoch 488/1000   error=0.008563\n",
            "epoch 489/1000   error=0.008544\n",
            "epoch 490/1000   error=0.008462\n",
            "epoch 491/1000   error=0.008469\n",
            "epoch 492/1000   error=0.008388\n",
            "epoch 493/1000   error=0.008352\n",
            "epoch 494/1000   error=0.008316\n",
            "epoch 495/1000   error=0.008250\n",
            "epoch 496/1000   error=0.008213\n",
            "epoch 497/1000   error=0.008195\n",
            "epoch 498/1000   error=0.008158\n",
            "epoch 499/1000   error=0.008100\n",
            "epoch 500/1000   error=0.008063\n",
            "epoch 501/1000   error=0.008002\n",
            "epoch 502/1000   error=0.007976\n",
            "epoch 503/1000   error=0.007960\n",
            "epoch 504/1000   error=0.007905\n",
            "epoch 505/1000   error=0.007871\n",
            "epoch 506/1000   error=0.007801\n",
            "epoch 507/1000   error=0.007781\n",
            "epoch 508/1000   error=0.007750\n",
            "epoch 509/1000   error=0.007711\n",
            "epoch 510/1000   error=0.007698\n",
            "epoch 511/1000   error=0.007615\n",
            "epoch 512/1000   error=0.007610\n",
            "epoch 513/1000   error=0.007560\n",
            "epoch 514/1000   error=0.007494\n",
            "epoch 515/1000   error=0.007534\n",
            "epoch 516/1000   error=0.007440\n",
            "epoch 517/1000   error=0.007442\n",
            "epoch 518/1000   error=0.007378\n",
            "epoch 519/1000   error=0.007315\n",
            "epoch 520/1000   error=0.007346\n",
            "epoch 521/1000   error=0.007286\n",
            "epoch 522/1000   error=0.007267\n",
            "epoch 523/1000   error=0.007205\n",
            "epoch 524/1000   error=0.007164\n",
            "epoch 525/1000   error=0.007163\n",
            "epoch 526/1000   error=0.007103\n",
            "epoch 527/1000   error=0.007094\n",
            "epoch 528/1000   error=0.007061\n",
            "epoch 529/1000   error=0.007020\n",
            "epoch 530/1000   error=0.006999\n",
            "epoch 531/1000   error=0.006942\n",
            "epoch 532/1000   error=0.006933\n",
            "epoch 533/1000   error=0.006901\n",
            "epoch 534/1000   error=0.006872\n",
            "epoch 535/1000   error=0.006841\n",
            "epoch 536/1000   error=0.006791\n",
            "epoch 537/1000   error=0.006768\n",
            "epoch 538/1000   error=0.006747\n",
            "epoch 539/1000   error=0.006737\n",
            "epoch 540/1000   error=0.006689\n",
            "epoch 541/1000   error=0.006655\n",
            "epoch 542/1000   error=0.006624\n",
            "epoch 543/1000   error=0.006599\n",
            "epoch 544/1000   error=0.006589\n",
            "epoch 545/1000   error=0.006520\n",
            "epoch 546/1000   error=0.006540\n",
            "epoch 547/1000   error=0.006486\n",
            "epoch 548/1000   error=0.006457\n",
            "epoch 549/1000   error=0.006446\n",
            "epoch 550/1000   error=0.006394\n",
            "epoch 551/1000   error=0.006396\n",
            "epoch 552/1000   error=0.006347\n",
            "epoch 553/1000   error=0.006332\n",
            "epoch 554/1000   error=0.006304\n",
            "epoch 555/1000   error=0.006262\n",
            "epoch 556/1000   error=0.006274\n",
            "epoch 557/1000   error=0.006214\n",
            "epoch 558/1000   error=0.006187\n",
            "epoch 559/1000   error=0.006192\n",
            "epoch 560/1000   error=0.006137\n",
            "epoch 561/1000   error=0.006143\n",
            "epoch 562/1000   error=0.006087\n",
            "epoch 563/1000   error=0.006073\n",
            "epoch 564/1000   error=0.006056\n",
            "epoch 565/1000   error=0.006012\n",
            "epoch 566/1000   error=0.006022\n",
            "epoch 567/1000   error=0.005975\n",
            "epoch 568/1000   error=0.005955\n",
            "epoch 569/1000   error=0.005935\n",
            "epoch 570/1000   error=0.005898\n",
            "epoch 571/1000   error=0.005878\n",
            "epoch 572/1000   error=0.005873\n",
            "epoch 573/1000   error=0.005845\n",
            "epoch 574/1000   error=0.005818\n",
            "epoch 575/1000   error=0.005793\n",
            "epoch 576/1000   error=0.005764\n",
            "epoch 577/1000   error=0.005747\n",
            "epoch 578/1000   error=0.005727\n",
            "epoch 579/1000   error=0.005713\n",
            "epoch 580/1000   error=0.005690\n",
            "epoch 581/1000   error=0.005657\n",
            "epoch 582/1000   error=0.005637\n",
            "epoch 583/1000   error=0.005619\n",
            "epoch 584/1000   error=0.005604\n",
            "epoch 585/1000   error=0.005565\n",
            "epoch 586/1000   error=0.005568\n",
            "epoch 587/1000   error=0.005534\n",
            "epoch 588/1000   error=0.005518\n",
            "epoch 589/1000   error=0.005483\n",
            "epoch 590/1000   error=0.005468\n",
            "epoch 591/1000   error=0.005454\n",
            "epoch 592/1000   error=0.005443\n",
            "epoch 593/1000   error=0.005426\n",
            "epoch 594/1000   error=0.005385\n",
            "epoch 595/1000   error=0.005375\n",
            "epoch 596/1000   error=0.005354\n",
            "epoch 597/1000   error=0.005337\n",
            "epoch 598/1000   error=0.005324\n",
            "epoch 599/1000   error=0.005291\n",
            "epoch 600/1000   error=0.005285\n",
            "epoch 601/1000   error=0.005257\n",
            "epoch 602/1000   error=0.005226\n",
            "epoch 603/1000   error=0.005230\n",
            "epoch 604/1000   error=0.005194\n",
            "epoch 605/1000   error=0.005206\n",
            "epoch 606/1000   error=0.005163\n",
            "epoch 607/1000   error=0.005137\n",
            "epoch 608/1000   error=0.005134\n",
            "epoch 609/1000   error=0.005109\n",
            "epoch 610/1000   error=0.005108\n",
            "epoch 611/1000   error=0.005073\n",
            "epoch 612/1000   error=0.005055\n",
            "epoch 613/1000   error=0.005049\n",
            "epoch 614/1000   error=0.005018\n",
            "epoch 615/1000   error=0.004994\n",
            "epoch 616/1000   error=0.004995\n",
            "epoch 617/1000   error=0.004964\n",
            "epoch 618/1000   error=0.004982\n",
            "epoch 619/1000   error=0.004932\n",
            "epoch 620/1000   error=0.004917\n",
            "epoch 621/1000   error=0.004910\n",
            "epoch 622/1000   error=0.004880\n",
            "epoch 623/1000   error=0.004887\n",
            "epoch 624/1000   error=0.004850\n",
            "epoch 625/1000   error=0.004842\n",
            "epoch 626/1000   error=0.004828\n",
            "epoch 627/1000   error=0.004799\n",
            "epoch 628/1000   error=0.004789\n",
            "epoch 629/1000   error=0.004774\n",
            "epoch 630/1000   error=0.004763\n",
            "epoch 631/1000   error=0.004756\n",
            "epoch 632/1000   error=0.004720\n",
            "epoch 633/1000   error=0.004714\n",
            "epoch 634/1000   error=0.004700\n",
            "epoch 635/1000   error=0.004672\n",
            "epoch 636/1000   error=0.004682\n",
            "epoch 637/1000   error=0.004647\n",
            "epoch 638/1000   error=0.004641\n",
            "epoch 639/1000   error=0.004624\n",
            "epoch 640/1000   error=0.004598\n",
            "epoch 641/1000   error=0.004591\n",
            "epoch 642/1000   error=0.004577\n",
            "epoch 643/1000   error=0.004569\n",
            "epoch 644/1000   error=0.004556\n",
            "epoch 645/1000   error=0.004530\n",
            "epoch 646/1000   error=0.004520\n",
            "epoch 647/1000   error=0.004505\n",
            "epoch 648/1000   error=0.004493\n",
            "epoch 649/1000   error=0.004469\n",
            "epoch 650/1000   error=0.004467\n",
            "epoch 651/1000   error=0.004448\n",
            "epoch 652/1000   error=0.004445\n",
            "epoch 653/1000   error=0.004418\n",
            "epoch 654/1000   error=0.004405\n",
            "epoch 655/1000   error=0.004391\n",
            "epoch 656/1000   error=0.004388\n",
            "epoch 657/1000   error=0.004371\n",
            "epoch 658/1000   error=0.004354\n",
            "epoch 659/1000   error=0.004340\n",
            "epoch 660/1000   error=0.004325\n",
            "epoch 661/1000   error=0.004317\n",
            "epoch 662/1000   error=0.004292\n",
            "epoch 663/1000   error=0.004295\n",
            "epoch 664/1000   error=0.004272\n",
            "epoch 665/1000   error=0.004269\n",
            "epoch 666/1000   error=0.004249\n",
            "epoch 667/1000   error=0.004233\n",
            "epoch 668/1000   error=0.004220\n",
            "epoch 669/1000   error=0.004218\n",
            "epoch 670/1000   error=0.004201\n",
            "epoch 671/1000   error=0.004189\n",
            "epoch 672/1000   error=0.004172\n",
            "epoch 673/1000   error=0.004158\n",
            "epoch 674/1000   error=0.004152\n",
            "epoch 675/1000   error=0.004133\n",
            "epoch 676/1000   error=0.004130\n",
            "epoch 677/1000   error=0.004108\n",
            "epoch 678/1000   error=0.004107\n",
            "epoch 679/1000   error=0.004089\n",
            "epoch 680/1000   error=0.004073\n",
            "epoch 681/1000   error=0.004071\n",
            "epoch 682/1000   error=0.004049\n",
            "epoch 683/1000   error=0.004046\n",
            "epoch 684/1000   error=0.004031\n",
            "epoch 685/1000   error=0.004016\n",
            "epoch 686/1000   error=0.004007\n",
            "epoch 687/1000   error=0.003994\n",
            "epoch 688/1000   error=0.003978\n",
            "epoch 689/1000   error=0.003983\n",
            "epoch 690/1000   error=0.003956\n",
            "epoch 691/1000   error=0.003958\n",
            "epoch 692/1000   error=0.003938\n",
            "epoch 693/1000   error=0.003924\n",
            "epoch 694/1000   error=0.003923\n",
            "epoch 695/1000   error=0.003901\n",
            "epoch 696/1000   error=0.003895\n",
            "epoch 697/1000   error=0.003886\n",
            "epoch 698/1000   error=0.003867\n",
            "epoch 699/1000   error=0.003874\n",
            "epoch 700/1000   error=0.003850\n",
            "epoch 701/1000   error=0.003835\n",
            "epoch 702/1000   error=0.003840\n",
            "epoch 703/1000   error=0.003814\n",
            "epoch 704/1000   error=0.003818\n",
            "epoch 705/1000   error=0.003798\n",
            "epoch 706/1000   error=0.003784\n",
            "epoch 707/1000   error=0.003784\n",
            "epoch 708/1000   error=0.003764\n",
            "epoch 709/1000   error=0.003759\n",
            "epoch 710/1000   error=0.003749\n",
            "epoch 711/1000   error=0.003731\n",
            "epoch 712/1000   error=0.003739\n",
            "epoch 713/1000   error=0.003715\n",
            "epoch 714/1000   error=0.003701\n",
            "epoch 715/1000   error=0.003706\n",
            "epoch 716/1000   error=0.003684\n",
            "epoch 717/1000   error=0.003684\n",
            "epoch 718/1000   error=0.003666\n",
            "epoch 719/1000   error=0.003656\n",
            "epoch 720/1000   error=0.003653\n",
            "epoch 721/1000   error=0.003635\n",
            "epoch 722/1000   error=0.003633\n",
            "epoch 723/1000   error=0.003620\n",
            "epoch 724/1000   error=0.003607\n",
            "epoch 725/1000   error=0.003608\n",
            "epoch 726/1000   error=0.003588\n",
            "epoch 727/1000   error=0.003579\n",
            "epoch 728/1000   error=0.003575\n",
            "epoch 729/1000   error=0.003559\n",
            "epoch 730/1000   error=0.003560\n",
            "epoch 731/1000   error=0.003544\n",
            "epoch 732/1000   error=0.003533\n",
            "epoch 733/1000   error=0.003536\n",
            "epoch 734/1000   error=0.003514\n",
            "epoch 735/1000   error=0.003512\n",
            "epoch 736/1000   error=0.003500\n",
            "epoch 737/1000   error=0.003490\n",
            "epoch 738/1000   error=0.003486\n",
            "epoch 739/1000   error=0.003470\n",
            "epoch 740/1000   error=0.003465\n",
            "epoch 741/1000   error=0.003458\n",
            "epoch 742/1000   error=0.003442\n",
            "epoch 743/1000   error=0.003443\n",
            "epoch 744/1000   error=0.003428\n",
            "epoch 745/1000   error=0.003420\n",
            "epoch 746/1000   error=0.003418\n",
            "epoch 747/1000   error=0.003400\n",
            "epoch 748/1000   error=0.003398\n",
            "epoch 749/1000   error=0.003387\n",
            "epoch 750/1000   error=0.003380\n",
            "epoch 751/1000   error=0.003369\n",
            "epoch 752/1000   error=0.003360\n",
            "epoch 753/1000   error=0.003352\n",
            "epoch 754/1000   error=0.003352\n",
            "epoch 755/1000   error=0.003332\n",
            "epoch 756/1000   error=0.003333\n",
            "epoch 757/1000   error=0.003320\n",
            "epoch 758/1000   error=0.003314\n",
            "epoch 759/1000   error=0.003307\n",
            "epoch 760/1000   error=0.003293\n",
            "epoch 761/1000   error=0.003290\n",
            "epoch 762/1000   error=0.003282\n",
            "epoch 763/1000   error=0.003267\n",
            "epoch 764/1000   error=0.003270\n",
            "epoch 765/1000   error=0.003255\n",
            "epoch 766/1000   error=0.003250\n",
            "epoch 767/1000   error=0.003245\n",
            "epoch 768/1000   error=0.003229\n",
            "epoch 769/1000   error=0.003229\n",
            "epoch 770/1000   error=0.003219\n",
            "epoch 771/1000   error=0.003212\n",
            "epoch 772/1000   error=0.003201\n",
            "epoch 773/1000   error=0.003194\n",
            "epoch 774/1000   error=0.003187\n",
            "epoch 775/1000   error=0.003185\n",
            "epoch 776/1000   error=0.003168\n",
            "epoch 777/1000   error=0.003166\n",
            "epoch 778/1000   error=0.003157\n",
            "epoch 779/1000   error=0.003156\n",
            "epoch 780/1000   error=0.003140\n",
            "epoch 781/1000   error=0.003134\n",
            "epoch 782/1000   error=0.003127\n",
            "epoch 783/1000   error=0.003127\n",
            "epoch 784/1000   error=0.003116\n",
            "epoch 785/1000   error=0.003105\n",
            "epoch 786/1000   error=0.003100\n",
            "epoch 787/1000   error=0.003092\n",
            "epoch 788/1000   error=0.003087\n",
            "epoch 789/1000   error=0.003076\n",
            "epoch 790/1000   error=0.003072\n",
            "epoch 791/1000   error=0.003063\n",
            "epoch 792/1000   error=0.003061\n",
            "epoch 793/1000   error=0.003048\n",
            "epoch 794/1000   error=0.003044\n",
            "epoch 795/1000   error=0.003035\n",
            "epoch 796/1000   error=0.003033\n",
            "epoch 797/1000   error=0.003021\n",
            "epoch 798/1000   error=0.003016\n",
            "epoch 799/1000   error=0.003008\n",
            "epoch 800/1000   error=0.003008\n",
            "epoch 801/1000   error=0.002992\n",
            "epoch 802/1000   error=0.002990\n",
            "epoch 803/1000   error=0.002981\n",
            "epoch 804/1000   error=0.002980\n",
            "epoch 805/1000   error=0.002971\n",
            "epoch 806/1000   error=0.002961\n",
            "epoch 807/1000   error=0.002958\n",
            "epoch 808/1000   error=0.002948\n",
            "epoch 809/1000   error=0.002943\n",
            "epoch 810/1000   error=0.002936\n",
            "epoch 811/1000   error=0.002930\n",
            "epoch 812/1000   error=0.002922\n",
            "epoch 813/1000   error=0.002921\n",
            "epoch 814/1000   error=0.002908\n",
            "epoch 815/1000   error=0.002906\n",
            "epoch 816/1000   error=0.002896\n",
            "epoch 817/1000   error=0.002893\n",
            "epoch 818/1000   error=0.002885\n",
            "epoch 819/1000   error=0.002879\n",
            "epoch 820/1000   error=0.002871\n",
            "epoch 821/1000   error=0.002872\n",
            "epoch 822/1000   error=0.002858\n",
            "epoch 823/1000   error=0.002856\n",
            "epoch 824/1000   error=0.002846\n",
            "epoch 825/1000   error=0.002844\n",
            "epoch 826/1000   error=0.002838\n",
            "epoch 827/1000   error=0.002828\n",
            "epoch 828/1000   error=0.002827\n",
            "epoch 829/1000   error=0.002817\n",
            "epoch 830/1000   error=0.002808\n",
            "epoch 831/1000   error=0.002808\n",
            "epoch 832/1000   error=0.002798\n",
            "epoch 833/1000   error=0.002797\n",
            "epoch 834/1000   error=0.002791\n",
            "epoch 835/1000   error=0.002780\n",
            "epoch 836/1000   error=0.002780\n",
            "epoch 837/1000   error=0.002769\n",
            "epoch 838/1000   error=0.002765\n",
            "epoch 839/1000   error=0.002760\n",
            "epoch 840/1000   error=0.002753\n",
            "epoch 841/1000   error=0.002746\n",
            "epoch 842/1000   error=0.002746\n",
            "epoch 843/1000   error=0.002734\n",
            "epoch 844/1000   error=0.002733\n",
            "epoch 845/1000   error=0.002723\n",
            "epoch 846/1000   error=0.002720\n",
            "epoch 847/1000   error=0.002714\n",
            "epoch 848/1000   error=0.002707\n",
            "epoch 849/1000   error=0.002707\n",
            "epoch 850/1000   error=0.002696\n",
            "epoch 851/1000   error=0.002689\n",
            "epoch 852/1000   error=0.002688\n",
            "epoch 853/1000   error=0.002678\n",
            "epoch 854/1000   error=0.002677\n",
            "epoch 855/1000   error=0.002670\n",
            "epoch 856/1000   error=0.002663\n",
            "epoch 857/1000   error=0.002664\n",
            "epoch 858/1000   error=0.002652\n",
            "epoch 859/1000   error=0.002646\n",
            "epoch 860/1000   error=0.002644\n",
            "epoch 861/1000   error=0.002635\n",
            "epoch 862/1000   error=0.002635\n",
            "epoch 863/1000   error=0.002627\n",
            "epoch 864/1000   error=0.002620\n",
            "epoch 865/1000   error=0.002623\n",
            "epoch 866/1000   error=0.002609\n",
            "epoch 867/1000   error=0.002604\n",
            "epoch 868/1000   error=0.002602\n",
            "epoch 869/1000   error=0.002593\n",
            "epoch 870/1000   error=0.002598\n",
            "epoch 871/1000   error=0.002584\n",
            "epoch 872/1000   error=0.002580\n",
            "epoch 873/1000   error=0.002577\n",
            "epoch 874/1000   error=0.002568\n",
            "epoch 875/1000   error=0.002566\n",
            "epoch 876/1000   error=0.002560\n",
            "epoch 877/1000   error=0.002554\n",
            "epoch 878/1000   error=0.002554\n",
            "epoch 879/1000   error=0.002544\n",
            "epoch 880/1000   error=0.002540\n",
            "epoch 881/1000   error=0.002537\n",
            "epoch 882/1000   error=0.002528\n",
            "epoch 883/1000   error=0.002527\n",
            "epoch 884/1000   error=0.002520\n",
            "epoch 885/1000   error=0.002514\n",
            "epoch 886/1000   error=0.002516\n",
            "epoch 887/1000   error=0.002504\n",
            "epoch 888/1000   error=0.002501\n",
            "epoch 889/1000   error=0.002497\n",
            "epoch 890/1000   error=0.002489\n",
            "epoch 891/1000   error=0.002490\n",
            "epoch 892/1000   error=0.002482\n",
            "epoch 893/1000   error=0.002475\n",
            "epoch 894/1000   error=0.002478\n",
            "epoch 895/1000   error=0.002466\n",
            "epoch 896/1000   error=0.002463\n",
            "epoch 897/1000   error=0.002459\n",
            "epoch 898/1000   error=0.002451\n",
            "epoch 899/1000   error=0.002455\n",
            "epoch 900/1000   error=0.002444\n",
            "epoch 901/1000   error=0.002441\n",
            "epoch 902/1000   error=0.002437\n",
            "epoch 903/1000   error=0.002429\n",
            "epoch 904/1000   error=0.002426\n",
            "epoch 905/1000   error=0.002422\n",
            "epoch 906/1000   error=0.002414\n",
            "epoch 907/1000   error=0.002420\n",
            "epoch 908/1000   error=0.002407\n",
            "epoch 909/1000   error=0.002405\n",
            "epoch 910/1000   error=0.002401\n",
            "epoch 911/1000   error=0.002393\n",
            "epoch 912/1000   error=0.002390\n",
            "epoch 913/1000   error=0.002387\n",
            "epoch 914/1000   error=0.002379\n",
            "epoch 915/1000   error=0.002385\n",
            "epoch 916/1000   error=0.002372\n",
            "epoch 917/1000   error=0.002369\n",
            "epoch 918/1000   error=0.002366\n",
            "epoch 919/1000   error=0.002358\n",
            "epoch 920/1000   error=0.002358\n",
            "epoch 921/1000   error=0.002351\n",
            "epoch 922/1000   error=0.002345\n",
            "epoch 923/1000   error=0.002348\n",
            "epoch 924/1000   error=0.002337\n",
            "epoch 925/1000   error=0.002335\n",
            "epoch 926/1000   error=0.002331\n",
            "epoch 927/1000   error=0.002324\n",
            "epoch 928/1000   error=0.002324\n",
            "epoch 929/1000   error=0.002317\n",
            "epoch 930/1000   error=0.002312\n",
            "epoch 931/1000   error=0.002315\n",
            "epoch 932/1000   error=0.002304\n",
            "epoch 933/1000   error=0.002301\n",
            "epoch 934/1000   error=0.002298\n",
            "epoch 935/1000   error=0.002290\n",
            "epoch 936/1000   error=0.002293\n",
            "epoch 937/1000   error=0.002284\n",
            "epoch 938/1000   error=0.002282\n",
            "epoch 939/1000   error=0.002278\n",
            "epoch 940/1000   error=0.002271\n",
            "epoch 941/1000   error=0.002269\n",
            "epoch 942/1000   error=0.002265\n",
            "epoch 943/1000   error=0.002258\n",
            "epoch 944/1000   error=0.002262\n",
            "epoch 945/1000   error=0.002252\n",
            "epoch 946/1000   error=0.002250\n",
            "epoch 947/1000   error=0.002246\n",
            "epoch 948/1000   error=0.002239\n",
            "epoch 949/1000   error=0.002237\n",
            "epoch 950/1000   error=0.002234\n",
            "epoch 951/1000   error=0.002227\n",
            "epoch 952/1000   error=0.002231\n",
            "epoch 953/1000   error=0.002221\n",
            "epoch 954/1000   error=0.002219\n",
            "epoch 955/1000   error=0.002215\n",
            "epoch 956/1000   error=0.002208\n",
            "epoch 957/1000   error=0.002206\n",
            "epoch 958/1000   error=0.002203\n",
            "epoch 959/1000   error=0.002196\n",
            "epoch 960/1000   error=0.002201\n",
            "epoch 961/1000   error=0.002190\n",
            "epoch 962/1000   error=0.002188\n",
            "epoch 963/1000   error=0.002185\n",
            "epoch 964/1000   error=0.002178\n",
            "epoch 965/1000   error=0.002176\n",
            "epoch 966/1000   error=0.002173\n",
            "epoch 967/1000   error=0.002166\n",
            "epoch 968/1000   error=0.002172\n",
            "epoch 969/1000   error=0.002160\n",
            "epoch 970/1000   error=0.002159\n",
            "epoch 971/1000   error=0.002155\n",
            "epoch 972/1000   error=0.002149\n",
            "epoch 973/1000   error=0.002146\n",
            "epoch 974/1000   error=0.002143\n",
            "epoch 975/1000   error=0.002137\n",
            "epoch 976/1000   error=0.002144\n",
            "epoch 977/1000   error=0.002132\n",
            "epoch 978/1000   error=0.002130\n",
            "epoch 979/1000   error=0.002126\n",
            "epoch 980/1000   error=0.002120\n",
            "epoch 981/1000   error=0.002118\n",
            "epoch 982/1000   error=0.002115\n",
            "epoch 983/1000   error=0.002109\n",
            "epoch 984/1000   error=0.002113\n",
            "epoch 985/1000   error=0.002103\n",
            "epoch 986/1000   error=0.002105\n",
            "epoch 987/1000   error=0.002098\n",
            "epoch 988/1000   error=0.002092\n",
            "epoch 989/1000   error=0.002093\n",
            "epoch 990/1000   error=0.002087\n",
            "epoch 991/1000   error=0.002085\n",
            "epoch 992/1000   error=0.002082\n",
            "epoch 993/1000   error=0.002076\n",
            "epoch 994/1000   error=0.002074\n",
            "epoch 995/1000   error=0.002070\n",
            "epoch 996/1000   error=0.002065\n",
            "epoch 997/1000   error=0.002066\n",
            "epoch 998/1000   error=0.002059\n",
            "epoch 999/1000   error=0.002059\n",
            "epoch 1000/1000   error=0.002054\n",
            "[array([[0.06387329]]), array([[0.96810483]]), array([[0.96803937]]), array([[0.04553313]])]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "#from network import Network\n",
        "#from fc_layer import FCLayer\n",
        "#from activation_layer import ActivationLayer\n",
        "#from activations import tanh, tanh_prime\n",
        "#from losses import mse, mse_prime\n",
        "\n",
        "# training data\n",
        "x_train = np.array([[[0,0]], [[0,1]], [[1,0]], [[1,1]]])\n",
        "y_train = np.array([[[0]], [[1]], [[1]], [[0]]])\n",
        "\n",
        "# network\n",
        "net = Network()\n",
        "net.add(FCLayer(2, 3))\n",
        "net.add(ActivationLayer(Relu, Relu_prime))\n",
        "net.add(FCLayer(3, 1))\n",
        "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
        "\n",
        "# train\n",
        "net.use(mse, mse_prime)\n",
        "net.fit(x_train, y_train, epochs=1000, learning_rate=0.1)\n",
        "\n",
        "# test\n",
        "out = net.predict(x_train)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV_wYxAK3wYr"
      },
      "source": [
        "### Solve MNIST\n",
        "We didn’t implemented the Convolutional Layer but this is not a problem. \n",
        "All we need to do is to reshape our data so that it can fit into a Fully Connected Layer.\n",
        "MNIST Dataset consists of images of digits from 0 to 9, of shape 28x28x1. \n",
        "The goal is to predict what digit is drawn on a picture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMAg7rm03wYs",
        "outputId": "f2fc8e1e-917f-4c0c-9ccd-28f4132338bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/35   error=0.092121\n",
            "epoch 2/35   error=0.061167\n",
            "epoch 3/35   error=0.047518\n",
            "epoch 4/35   error=0.038354\n",
            "epoch 5/35   error=0.030949\n",
            "epoch 6/35   error=0.025401\n",
            "epoch 7/35   error=0.021587\n",
            "epoch 8/35   error=0.018724\n",
            "epoch 9/35   error=0.016503\n",
            "epoch 10/35   error=0.014740\n",
            "epoch 11/35   error=0.013220\n",
            "epoch 12/35   error=0.012004\n",
            "epoch 13/35   error=0.010997\n",
            "epoch 14/35   error=0.010145\n",
            "epoch 15/35   error=0.009381\n",
            "epoch 16/35   error=0.008662\n",
            "epoch 17/35   error=0.008055\n",
            "epoch 18/35   error=0.007537\n",
            "epoch 19/35   error=0.007098\n",
            "epoch 20/35   error=0.006676\n",
            "epoch 21/35   error=0.006219\n",
            "epoch 22/35   error=0.005779\n",
            "epoch 23/35   error=0.005409\n",
            "epoch 24/35   error=0.005108\n",
            "epoch 25/35   error=0.004854\n",
            "epoch 26/35   error=0.004617\n",
            "epoch 27/35   error=0.004406\n",
            "epoch 28/35   error=0.004210\n",
            "epoch 29/35   error=0.004028\n",
            "epoch 30/35   error=0.003874\n",
            "epoch 31/35   error=0.003743\n",
            "epoch 32/35   error=0.003622\n",
            "epoch 33/35   error=0.003505\n",
            "epoch 34/35   error=0.003400\n",
            "epoch 35/35   error=0.003303\n",
            "\n",
            "\n",
            "predicted values : \n",
            "[array([[4.72284862e-03, 8.96593091e-05, 2.26328231e-01, 1.96520385e-02,\n",
            "        4.09721193e-04, 3.23368536e-03, 5.47998151e-05, 9.88352282e-01,\n",
            "        4.20381575e-03, 3.34872092e-03]]), array([[2.51252212e-02, 8.81687238e-04, 3.48760273e-01, 1.47512963e-03,\n",
            "        3.65257226e-05, 8.14152527e-02, 7.98952821e-01, 2.67715072e-02,\n",
            "        7.24252385e-03, 2.63049837e-04]]), array([[8.37425202e-05, 9.60866558e-01, 4.12710275e-03, 2.41840355e-03,\n",
            "        1.90167762e-03, 3.49951890e-03, 1.51024580e-02, 5.39849481e-02,\n",
            "        1.81995681e-03, 2.24267521e-02]])]\n",
            "true values : \n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "#from network import Network\n",
        "#from fc_layer import FCLayer\n",
        "#from activation_layer import ActivationLayer\n",
        "#from activations import tanh, tanh_prime\n",
        "#from losses import mse, mse_prime\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# load MNIST from server\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# training data : 60000 samples\n",
        "# reshape and normalize input data\n",
        "x_train = x_train.reshape(x_train.shape[0], 1, 28*28)\n",
        "x_train = x_train.astype('float32')\n",
        "x_train /= 255\n",
        "# encode output which is a number in range [0,9] into a vector of size 10\n",
        "# e.g. number 3 will become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "\n",
        "# same for test data : 10000 samples\n",
        "x_test = x_test.reshape(x_test.shape[0], 1, 28*28)\n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# Network\n",
        "net = Network()\n",
        "net.add(FCLayer(28*28, 100))                # input_shape=(1, 28*28)    ;   output_shape=(1, 100)\n",
        "net.add(ActivationLayer(Relu, Relu_prime))\n",
        "net.add(FCLayer(100, 50))                   # input_shape=(1, 100)      ;   output_shape=(1, 50)\n",
        "net.add(ActivationLayer(tanh, tanh_prime))\n",
        "net.add(FCLayer(50, 10))                    # input_shape=(1, 50)       ;   output_shape=(1, 10)\n",
        "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
        "\n",
        "# train on 1000 samples\n",
        "# as we didn't implemented mini-batch GD, training will be pretty slow if we update at each iteration on 60000 samples...\n",
        "net.use(mse, mse_prime)\n",
        "net.fit(x_train[0:1000], y_train[0:1000], epochs=35, learning_rate=0.1)\n",
        "\n",
        "# test on 3 samples\n",
        "out = net.predict(x_test[0:3])\n",
        "print(\"\\n\")\n",
        "print(\"predicted values : \")\n",
        "print(out, end=\"\\n\")\n",
        "print(\"true values : \")\n",
        "print(y_test[0:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZeDp5nT3wYv",
        "outputId": "6d2a55e7-d2e8-4a45-f9f0-9d4f44f21c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]]]\n"
          ]
        }
      ],
      "source": [
        "#*************** deneme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1v6oFjqB3wYw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model object\n",
        "model = tf.keras.Sequential()"
      ],
      "metadata": {
        "id": "nB9zd7azTAER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an input layer\n",
        "input_layer = tf.keras.layers.Dense(4096, input_shape=(34,), activation = 'relu')\n",
        "\n",
        "# Add input layer to model object\n",
        "model.add(input_layer)"
      ],
      "metadata": {
        "id": "6sqSk9tSTABt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the first hidden layer with 4096 nodes and relu activation function\n",
        "model.add(tf.keras.layers.Dense(4096,activation='relu' ))\n",
        "# Add 0.5 dropout\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "# Add the second hidden layer with 4096 nodes and relu activation function\n",
        "model.add(tf.keras.layers.Dense(4096,activation= 'relu'))\n",
        "# Add 0.5 dropout\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "# Add the third hidden layer with 4096 nodes and relu activation function\n",
        "model.add(tf.keras.layers.Dense(4096, activation = 'relu'))\n",
        "# Add 0.5 dropout\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "# Add the fourth hidden layer with 4096 nodes and relu activation function\n",
        "model.add(tf.keras.layers.Dense(4096, activation = 'relu'))\n",
        "# Add 0.5 dropout\n",
        "model.add(tf.keras.layers.Dropout(0.5))"
      ],
      "metadata": {
        "id": "rv5ZCRSaS__1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the output layer\n",
        "model.add((tf.keras.layers.Dense(7,activation= 'sigmoid')))"
      ],
      "metadata": {
        "id": "yWIUB5npS_9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer= 'adam',loss='sparse_categorical_crosssentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "0yDmRgyRS_7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Relu(x):\n",
        "  return (np.maximum(0,x))"
      ],
      "metadata": {
        "id": "fqN0JUQ-lpia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Relu(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53FRscQdoUpP",
        "outputId": "44890a03-969c-46a8-8b2b-103d208a39d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.00000000e+00, 0.00000000e+00, 9.13950635e-03, 0.00000000e+00,\n",
              "         0.00000000e+00, 3.31557664e-02, 1.24326872e-03, 9.46212371e-01,\n",
              "         4.61049064e-02, 0.00000000e+00]],\n",
              "\n",
              "       [[6.39176654e-01, 8.59287947e-04, 3.50408496e-01, 2.05577367e-01,\n",
              "         3.50042524e-04, 1.46916474e-01, 4.99143692e-02, 0.00000000e+00,\n",
              "         2.02294101e-01, 0.00000000e+00]],\n",
              "\n",
              "       [[0.00000000e+00, 9.69141410e-01, 0.00000000e+00, 5.86614302e-04,\n",
              "         0.00000000e+00, 3.58262614e-02, 9.31574587e-03, 2.16806137e-02,\n",
              "         2.24608761e-02, 0.00000000e+00]]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Relu(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH-8hy12o1t1",
        "outputId": "2bb1c051-b2cc-4e09-90e5-b641c655463f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Relu(net.fit(x_train[0:1000], y_train[0:1000], epochs=30, learning_rate=0.4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "id": "Ebr9PoqwnCBU",
        "outputId": "6bd38676-16e6-4618-910a-6b182937e836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/30   error=0.389830\n",
            "epoch 2/30   error=0.388893\n",
            "epoch 3/30   error=0.355355\n",
            "epoch 4/30   error=0.313085\n",
            "epoch 5/30   error=0.313995\n",
            "epoch 6/30   error=0.279213\n",
            "epoch 7/30   error=0.276015\n",
            "epoch 8/30   error=0.274463\n",
            "epoch 9/30   error=0.265774\n",
            "epoch 10/30   error=0.262936\n",
            "epoch 11/30   error=0.263309\n",
            "epoch 12/30   error=0.262655\n",
            "epoch 13/30   error=0.262807\n",
            "epoch 14/30   error=0.258354\n",
            "epoch 15/30   error=0.260744\n",
            "epoch 16/30   error=0.250679\n",
            "epoch 17/30   error=0.252270\n",
            "epoch 18/30   error=0.253737\n",
            "epoch 19/30   error=0.245494\n",
            "epoch 20/30   error=0.243576\n",
            "epoch 21/30   error=0.244558\n",
            "epoch 22/30   error=0.246718\n",
            "epoch 23/30   error=0.252411\n",
            "epoch 24/30   error=0.236109\n",
            "epoch 25/30   error=0.236762\n",
            "epoch 26/30   error=0.243511\n",
            "epoch 27/30   error=0.243719\n",
            "epoch 28/30   error=0.233495\n",
            "epoch 29/30   error=0.224605\n",
            "epoch 30/30   error=0.224174\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-3f8db95405d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-aec154eb811b>\u001b[0m in \u001b[0;36mRelu\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mRelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'int' and 'NoneType'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "print(sigmoid(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRw706uwvdWT",
        "outputId": "a5ca3a1a-e90b-4ef8-bfa2-f92553df9b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5       0.5       0.5       ... 0.7310586 0.5       0.5      ]\n",
            " [0.5       0.5       0.7310586 ... 0.5       0.5       0.5      ]\n",
            " [0.5       0.7310586 0.5       ... 0.5       0.5       0.5      ]\n",
            " ...\n",
            " [0.5       0.5       0.5       ... 0.5       0.5       0.5      ]\n",
            " [0.5       0.5       0.5       ... 0.5       0.5       0.5      ]\n",
            " [0.5       0.5       0.5       ... 0.5       0.5       0.5      ]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}